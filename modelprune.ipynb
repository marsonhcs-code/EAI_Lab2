{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lk6d9yOhuSkr"
   },
   "source": [
    "## 掛載雲端硬碟"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "3NTpFfZGuVSx"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VEETyGg0uZnb"
   },
   "source": [
    "## 更改檔案所在路徑\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Wum2GQmwucfZ"
   },
   "outputs": [],
   "source": [
    "# Change to your own folder !!!\n",
    "# %cd /content/drive/MyDrive/your own folder/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S9NTZ1VEtbV7"
   },
   "source": [
    "## 載入函式庫\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "vCvF-fM0tfsq"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "\n",
    "from models.resnet import ResNet50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_X_r4dtMuwbh"
   },
   "source": [
    "## 超參數設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "_2NkY0LyuyQh"
   },
   "outputs": [],
   "source": [
    "DATASET = 'cifar10'\n",
    "TEST_BATCH_SIZE = 1000\n",
    "CUDA = True\n",
    "PRUNE_PERCENT = 0.9 # Change your prune ratio!\n",
    "WEIGHT_PATH = 'model_best.pth' # Change to your own folder !!!\n",
    "PRUNE_PATH = 'model_prune.pth' # Change to your own folder !!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L7z4dkhJwB4Z"
   },
   "source": [
    "## 載入模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/n26141826/EAI_Lab2/.venv/bin/python\n",
      "Location: /home/n26141826/EAI_Lab2/.venv/lib/python3.12/site-packages\n",
      "2.6.0+cu124\n",
      "2.6.0+cu124\n",
      "12.4\n",
      "True\n",
      "✅ CUDA OK: cuda:0 0.7797485589981079\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "\n",
    "!pip show torch | grep Location\n",
    "!python -c \"import torch; print(torch.__version__)\"\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "print(torch.cuda.is_available())\n",
    "x = torch.randn(5, 5).cuda()\n",
    "print(\"✅ CUDA OK:\", x.device, x.sum().item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "lpIqnhfKwEcJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOADING CHECKPOINT model_best.pth @EPOCH=36, BEST_PREC1=0.9119\n",
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "CUDA = CUDA and torch.cuda.is_available()\n",
    "\n",
    "model = ResNet50(num_classes=10)\n",
    "for name, param in model.named_parameters():\n",
    "    if param.numel() == 0:\n",
    "        print(f\"[ERROR] Empty tensor detected at {name}, shape={param.shape}\")\n",
    "\n",
    "if CUDA:\n",
    "    model.cuda()\n",
    "\n",
    "if WEIGHT_PATH:\n",
    "    if os.path.isfile(WEIGHT_PATH):\n",
    "        checkpoint = torch.load(WEIGHT_PATH)\n",
    "        best_prec1 = checkpoint['best_prec1']\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        print('LOADING CHECKPOINT {} @EPOCH={}, BEST_PREC1={}'.format(WEIGHT_PATH,checkpoint['epoch'],best_prec1))\n",
    "\n",
    "    else:\n",
    "        print(\"NO CHECKPOINT FOUND\")\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "srauYOD-1vSp"
   },
   "source": [
    "## 進行剪枝\n",
    "#### 計算所有Batch Normalizaiton中的scale factor絕對值大小並排序\n",
    "#### 利用設定好的PRUNE_PERCENT來取得閥值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "xgtUBaDw1uuR"
   },
   "outputs": [],
   "source": [
    "total = 0\n",
    "for m in model.modules():\n",
    "    if isinstance(m, nn.BatchNorm2d):\n",
    "        total += m.weight.data.shape[0]\n",
    "\n",
    "bn = torch.zeros(total)\n",
    "index = 0\n",
    "for m in model.modules():\n",
    "    if isinstance(m, nn.BatchNorm2d):\n",
    "        size = m.weight.data.shape[0]\n",
    "        bn[index:(index+size)] = m.weight.data.abs().clone()\n",
    "        index += size\n",
    "\n",
    "y, i = torch.sort(bn)\n",
    "\n",
    "threshold_index = int(total * PRUNE_PERCENT)\n",
    "threshold = y[threshold_index]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "66vDWd5BMmph"
   },
   "source": [
    "## 根據Batch Normalization Layer資訊建立CONFIG\n",
    "#### 1. 複製Batch Normalization Layer的weight(也就是scale factor γ)\n",
    "#### 2. 建立mask，大於threshold的index的值會設成1,小於threshold的值會設成0\n",
    "#### 3. mask的值加總後，會是剪枝後Layer對應的輸出channel數\n",
    "#### 4. 最後得到要建立剪枝模型的CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "PBklaqUZHnvp"
   },
   "outputs": [],
   "source": [
    "pruned = 0\n",
    "cfg = []  #用來建立剪枝網路的CONFIG\n",
    "cfg_mask = [] #用來幫助剪枝的遮罩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cfg_index: 1 -> layer index: bn1, preserved=False, total channel: 64, remaining channel: 64\n",
      "cfg_index: 2 -> layer index: layer1.0.bn1, preserved=False, total channel: 64, remaining channel: 64\n",
      "cfg_index: 3 -> layer index: layer1.0.bn2, preserved=False, total channel: 64, remaining channel: 64\n",
      "cfg_index: 4 -> layer index: layer1.0.bn3, preserved=False, total channel: 256, remaining channel: 256\n",
      "cfg_index: 5 -> layer index: layer1.1.bn1, preserved=False, total channel: 64, remaining channel: 64\n",
      "cfg_index: 6 -> layer index: layer1.1.bn2, preserved=False, total channel: 64, remaining channel: 64\n",
      "cfg_index: 7 -> layer index: layer1.1.bn3, preserved=False, total channel: 256, remaining channel: 256\n",
      "cfg_index: 8 -> layer index: layer1.2.bn1, preserved=False, total channel: 64, remaining channel: 64\n",
      "cfg_index: 9 -> layer index: layer1.2.bn2, preserved=False, total channel: 64, remaining channel: 64\n",
      "cfg_index: 10 -> layer index: layer1.2.bn3, preserved=False, total channel: 256, remaining channel: 256\n",
      "cfg_index: 11 -> layer index: layer2.0.bn1, preserved=False, total channel: 128, remaining channel: 117\n",
      "cfg_index: 12 -> layer index: layer2.0.bn2, preserved=False, total channel: 128, remaining channel: 121\n",
      "cfg_index: 13 -> layer index: layer2.0.bn3, preserved=False, total channel: 512, remaining channel: 512\n",
      "cfg_index: 14 -> layer index: layer2.1.bn1, preserved=False, total channel: 128, remaining channel: 92\n",
      "cfg_index: 15 -> layer index: layer2.1.bn2, preserved=False, total channel: 128, remaining channel: 121\n",
      "cfg_index: 16 -> layer index: layer2.1.bn3, preserved=False, total channel: 512, remaining channel: 512\n",
      "cfg_index: 17 -> layer index: layer2.2.bn1, preserved=False, total channel: 128, remaining channel: 69\n",
      "cfg_index: 18 -> layer index: layer2.2.bn2, preserved=False, total channel: 128, remaining channel: 75\n",
      "cfg_index: 19 -> layer index: layer2.2.bn3, preserved=False, total channel: 512, remaining channel: 512\n",
      "cfg_index: 20 -> layer index: layer2.3.bn1, preserved=False, total channel: 128, remaining channel: 69\n",
      "cfg_index: 21 -> layer index: layer2.3.bn2, preserved=False, total channel: 128, remaining channel: 71\n",
      "cfg_index: 22 -> layer index: layer2.3.bn3, preserved=False, total channel: 512, remaining channel: 512\n",
      "cfg_index: 23 -> layer index: layer3.0.bn1, preserved=False, total channel: 256, remaining channel: 66\n",
      "cfg_index: 24 -> layer index: layer3.0.bn2, preserved=False, total channel: 256, remaining channel: 63\n",
      "cfg_index: 25 -> layer index: layer3.0.bn3, preserved=False, total channel: 1024, remaining channel: 1024\n",
      "cfg_index: 26 -> layer index: layer3.1.bn1, preserved=False, total channel: 256, remaining channel: 14\n",
      "cfg_index: 27 -> layer index: layer3.1.bn2, preserved=False, total channel: 256, remaining channel: 24\n",
      "cfg_index: 28 -> layer index: layer3.1.bn3, preserved=False, total channel: 1024, remaining channel: 1024\n",
      "cfg_index: 29 -> layer index: layer3.2.bn1, preserved=False, total channel: 256, remaining channel: 1\n",
      "cfg_index: 30 -> layer index: layer3.2.bn2, preserved=False, total channel: 256, remaining channel: 8\n",
      "cfg_index: 31 -> layer index: layer3.2.bn3, preserved=False, total channel: 1024, remaining channel: 1024\n",
      "cfg_index: 32 -> layer index: layer3.3.bn1, preserved=False, total channel: 256, remaining channel: 1\n",
      "cfg_index: 33 -> layer index: layer3.3.bn2, preserved=False, total channel: 256, remaining channel: 8\n",
      "cfg_index: 34 -> layer index: layer3.3.bn3, preserved=False, total channel: 1024, remaining channel: 1024\n",
      "cfg_index: 35 -> layer index: layer3.4.bn1, preserved=False, total channel: 256, remaining channel: 3\n",
      "cfg_index: 36 -> layer index: layer3.4.bn2, preserved=False, total channel: 256, remaining channel: 2\n",
      "cfg_index: 37 -> layer index: layer3.4.bn3, preserved=False, total channel: 1024, remaining channel: 1024\n",
      "cfg_index: 38 -> layer index: layer3.5.bn1, preserved=False, total channel: 256, remaining channel: 3\n",
      "cfg_index: 39 -> layer index: layer3.5.bn2, preserved=False, total channel: 256, remaining channel: 3\n",
      "cfg_index: 40 -> layer index: layer3.5.bn3, preserved=False, total channel: 1024, remaining channel: 1024\n",
      "cfg_index: 41 -> layer index: layer4.0.bn1, preserved=False, total channel: 512, remaining channel: 4\n",
      "cfg_index: 42 -> layer index: layer4.0.bn2, preserved=False, total channel: 512, remaining channel: 2\n",
      "cfg_index: 43 -> layer index: layer4.0.bn3, preserved=False, total channel: 2048, remaining channel: 2048\n",
      "cfg_index: 44 -> layer index: layer4.1.bn1, preserved=False, total channel: 512, remaining channel: 3\n",
      "cfg_index: 45 -> layer index: layer4.1.bn2, preserved=False, total channel: 512, remaining channel: 3\n",
      "cfg_index: 46 -> layer index: layer4.1.bn3, preserved=False, total channel: 2048, remaining channel: 2048\n",
      "cfg_index: 47 -> layer index: layer4.2.bn1, preserved=False, total channel: 512, remaining channel: 3\n",
      "cfg_index: 48 -> layer index: layer4.2.bn2, preserved=False, total channel: 512, remaining channel: 3\n",
      "cfg_index: 49 -> layer index: layer4.2.bn3, preserved=False, total channel: 2048, remaining channel: 2048\n",
      "PRUNE RATIO=0.0\n",
      "PREPROCESSING SUCCESSFUL!\n",
      "cfg: [64, 64, 64, 256, 64, 64, 256, 64, 64, 256, 117, 121, 512, 92, 121, 512, 69, 75, 512, 69, 71, 512, 66, 63, 1024, 14, 24, 1024, 1, 8, 1024, 1, 8, 1024, 3, 2, 1024, 3, 3, 1024, 4, 2, 2048, 3, 3, 2048, 3, 3, 2048]\n"
     ]
    }
   ],
   "source": [
    "cfg = []\n",
    "cfg_mask = []\n",
    "preserved_cfg_idx = []\n",
    "\n",
    "cfg_idx = 0\n",
    "for name, m in model.named_modules():\n",
    "    if isinstance(m, nn.BatchNorm2d):\n",
    "        if name.endswith(\"bn3\") or \"downsample.1\" in name:\n",
    "            if name.endswith(\"downsample.1\"):\n",
    "                continue\n",
    "            # preserve shortcut\n",
    "            mask = torch.ones_like(m.weight.data)\n",
    "            preserved_cfg_idx.append(cfg_idx)\n",
    "        else:\n",
    "            weight_copy = m.weight.data.clone()\n",
    "            if torch.any(torch.isnan(weight_copy)):\n",
    "                print(f\"[NaN Detected] in {name}\")\n",
    "            mask = weight_copy.abs().gt(threshold).float().cuda()\n",
    "            if int(torch.sum(mask)) == 0:\n",
    "                _, sorted_idx = torch.topk(weight_copy.abs(), 3)\n",
    "                mask[sorted_idx] = 1.0\n",
    "\n",
    "        # cfg_mask.append(mask.clone())\n",
    "        cfg_mask.append(mask.clone().cuda())\n",
    "        cfg.append(int(torch.sum(mask)))\n",
    "        cfg_idx += 1\n",
    "        print(f\"cfg_index: {cfg_idx} -> layer index: {name}, preserved={cfg_idx in preserved_cfg_idx}, total channel: {mask.shape[0]}, remaining channel: {int(torch.sum(mask))}\")\n",
    "\n",
    "\n",
    "pruned_ratio = pruned/total\n",
    "\n",
    "print(f'PRUNE RATIO={pruned_ratio}')\n",
    "print('PREPROCESSING SUCCESSFUL!')\n",
    "\n",
    "print(f'cfg: {cfg}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "10ilGgoZ1SR1"
   },
   "outputs": [],
   "source": [
    "# preserved_cfg_idx = [2,3,6,7,9,10,12,13,16,17,18,19,22,23,25,26,29,30,31,32,35,36,38,39,42,43,45,46,49,50]\n",
    "# bn_index = 0\n",
    "\n",
    "# for k, m in enumerate((model.modules())):\n",
    "#     if isinstance(m, nn.BatchNorm2d):\n",
    "#         weight_copy = m.weight.data.clone()\n",
    "#         # mask = weight_copy.abs().gt(threshold).float().cuda() # 大於 threshold 的設為 True (1.0)，其餘為 False(0.0)\n",
    "\n",
    "#         # 注意: 需自行設計處理剩下channel數為0的情況 (e.g. 至少保留3個channel)\n",
    "#         ################################################\n",
    "#         #          請填空          #\n",
    "#         ################################################\n",
    "#         if bn_index in preserved_cfg_idx:\n",
    "#             # 保留這些BN層（通常是Bottleneck中的最後一層）\n",
    "#             mask = torch.ones_like(weight_copy).cuda()\n",
    "#         else:\n",
    "#             # 否則就做 threshold-based pruning\n",
    "#             mask = weight_copy.abs().gt(threshold).float().cuda()\n",
    "\n",
    "#             # 若全部被剪掉，強制保留前三大（可調成至少3個）\n",
    "#             if int(torch.sum(mask)) == 0:\n",
    "#                 _, sorted_idx = torch.topk(weight_copy.abs(), 3)\n",
    "#                 mask[sorted_idx] = 1.0\n",
    "#         bn_index += 1\n",
    "\n",
    "\n",
    "#         # 處理剪枝後的權重\n",
    "#         m.weight.data.mul_(mask)\n",
    "#         m.bias.data.mul_(mask)\n",
    "#         pruned = pruned + mask.shape[0] - torch.sum(mask)\n",
    "#         cfg.append(int(torch.sum(mask)))    # 記錄每一層 BN 剩下幾個通道\n",
    "#         cfg_mask.append(mask.clone())     # 儲存每層對應的 mask\n",
    "#         # print('layer index: {:d} \\t total channel: {:d} \\t remaining channel: {:d}'.\n",
    "#         #     format(k, mask.shape[0], int(torch.sum(mask))))\n",
    "#         print(f\"cfg_index: {bn_index} -> layer index: {k}, preserved={bn_index in preserved_cfg_idx}, total channel: {mask.shape[0]}, remaining channel: {int(torch.sum(mask))}\")\n",
    "# pruned_ratio = pruned/total\n",
    "\n",
    "# print(f'PRUNE RATIO={pruned_ratio}')\n",
    "# print('PREPROCESSING SUCCESSFUL!')\n",
    "\n",
    "# print(f'cfg: {cfg}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ha2BuBl1ifM"
   },
   "source": [
    "## 建立剪枝模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "SlWNdj2f1nWs"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 117, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(117, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(117, 121, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(121, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(121, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 92, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(92, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(92, 121, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(121, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(121, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 69, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(69, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(69, 75, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(75, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(75, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 69, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(69, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(69, 71, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(71, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(71, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 66, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(66, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(66, 63, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(63, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(63, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 14, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(14, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(24, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(8, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(8, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(3, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(2, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(3, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(4, 2, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(2, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(3, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(3, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newmodel = ResNet50(num_classes=10, cfg=cfg, )\n",
    "newmodel.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ms9Usgkh1Vbe"
   },
   "source": [
    "### 將原本的模型權重複製到剪枝的模型\n",
    "#### 根據不同層決定要複製什麼權重\n",
    "###### Batch Normalization Layer\n",
    "1.   scale factor\n",
    "2.   bias\n",
    "3.   running mean\n",
    "4.   running variance\n",
    "\n",
    "###### Convolutional Layer\n",
    "1.   weight\n",
    "\n",
    "###### Linear Layer\n",
    "1.   weight\n",
    "2.   bias\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def transfer_pruned_weights(model, newmodel, cfg_mask):\n",
    "    model.eval()\n",
    "    newmodel.eval()\n",
    "    layer_id_in_cfg = 0      # 遮罩列表索引\n",
    "    prev_mask = torch.ones(1)  # 初始化前一層輸出遮罩，對於第一個卷積層的輸入（如RGB 3通道），用全1\n",
    "    for (name, m0) in model.named_modules():\n",
    "        m1 = dict(newmodel.named_modules()).get(name)\n",
    "        if m1 is None:\n",
    "            continue  # 新模型可能沒有對應模組（通常不會發生，因架構相同）\n",
    "        # 處理 BatchNorm2d 層\n",
    "        if isinstance(m0, torch.nn.BatchNorm2d):\n",
    "            if \"downsample.1\" in name:\n",
    "                # 捷徑 BN 層，不使用遮罩，直接複製\n",
    "                m1.weight.data.copy_(m0.weight.data)\n",
    "                m1.bias.data.copy_(m0.bias.data)\n",
    "                m1.running_mean.copy_(m0.running_mean)\n",
    "                m1.running_var.copy_(m0.running_var)\n",
    "            else:\n",
    "                # 非捷徑 BN 層，使用 cfg_mask 遮罩進行通道選擇\n",
    "                mask = cfg_mask[layer_id_in_cfg]  # 取出對應遮罩\n",
    "                idx = np.squeeze(np.argwhere(np.asarray(mask.cpu().numpy())))\n",
    "                if idx.size == 1:\n",
    "                    idx = np.resize(idx, (1,))\n",
    "                # 複製選定通道的 BN 參數\n",
    "                m1.weight.data = m0.weight.data[idx.tolist()].clone()\n",
    "                m1.bias.data   = m0.bias.data[idx.tolist()].clone()\n",
    "                m1.running_mean = m0.running_mean[idx.tolist()].clone()\n",
    "                m1.running_var  = m0.running_var[idx.tolist()].clone()\n",
    "                # 更新 prev_mask 為當前遮罩，供下一層卷積使用\n",
    "                prev_mask = mask.clone()\n",
    "                layer_id_in_cfg += 1\n",
    "        # 處理 Conv2d 層\n",
    "        elif isinstance(m0, torch.nn.Conv2d):\n",
    "            if \"downsample.0\" in name or m0.weight.data.shape == m1.weight.data.shape:\n",
    "                # 捷徑卷積層或未剪枝的卷積，直接完整拷貝權重（以及偏置）\n",
    "                m1.weight.data.copy_(m0.weight.data)\n",
    "                if m0.bias is not None:\n",
    "                    m1.bias.data.copy_(m0.bias.data)\n",
    "            else:\n",
    "                # 剪枝過的卷積層，按照 prev_mask 和下一遮罩進行權重拷貝\n",
    "                curr_mask = cfg_mask[layer_id_in_cfg]  # 注意：Conv緊隨上一個BN，layer_id_in_cfg尚未增1，此時取當前索引即下一層BN遮罩\n",
    "                # 提取索引列表\n",
    "                in_idx = np.squeeze(np.argwhere(np.asarray(prev_mask.cpu().numpy())))\n",
    "                out_idx = np.squeeze(np.argwhere(np.asarray(curr_mask.cpu().numpy())))\n",
    "                if in_idx.size == 1:\n",
    "                    in_idx = np.resize(in_idx, (1,))\n",
    "                if out_idx.size == 1:\n",
    "                    out_idx = np.resize(out_idx, (1,))\n",
    "                # 根據索引篩選權重張量並複製\n",
    "                w = m0.weight.data[:, in_idx.tolist(), :, :].clone()\n",
    "                w = w[out_idx.tolist(), :, :, :].clone()\n",
    "                m1.weight.data = w.clone()\n",
    "                # 複製偏置（若有）\n",
    "                if m0.bias is not None:\n",
    "                    b = m0.bias.data[out_idx.tolist()].clone()\n",
    "                    m1.bias.data = b.clone()\n",
    "                # **注意**：此處不增 layer_id_in_cfg，因為對應遮罩會在隨後的 BN 處理時增1\n",
    "        # 處理 Linear 層\n",
    "        elif isinstance(m0, torch.nn.Linear):\n",
    "            # 線性層未剪枝，直接拷貝權重和偏置\n",
    "            m1.weight.data.copy_(m0.weight.data)\n",
    "            m1.bias.data.copy_(m0.bias.data)\n",
    "\n",
    "# 執行範例\n",
    "transfer_pruned_weights(model, newmodel, cfg_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hQcKuMDee46V"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m0: Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "m1: Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "\n",
      "[Layer 1] Conv2d pruning\n",
      "start_mask: torch.Size([3]), sum=3.0\n",
      "type(end_mask)=<class 'torch.Tensor'> | device=cuda:0 | dtype=torch.float32\n",
      "end_mask (cpu): tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "end_mask shape: torch.Size([64]), sum=64.0\n",
      "end_mask: torch.Size([64]), sum=64.0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'old_bn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 28\u001b[39m\n\u001b[32m     22\u001b[39m     idx = np.resize(idx, (\u001b[32m1\u001b[39m,))\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# #### 複製weight, bias, running mean,and running variance ####\u001b[39;00m\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# ################################################\u001b[39;00m\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# #          請填空          #\u001b[39;00m\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# ################################################\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m new_bn.weight.data = \u001b[43mold_bn\u001b[49m.weight.data[idx.tolist()].clone()\n\u001b[32m     29\u001b[39m new_bn.bias.data   = old_bn.bias.data[idx.tolist()].clone()\n\u001b[32m     30\u001b[39m new_bn.running_mean = old_bn.running_mean[idx.tolist()].clone()\n",
      "\u001b[31mNameError\u001b[39m: name 'old_bn' is not defined"
     ]
    }
   ],
   "source": [
    "# old_modules = list(model.modules())\n",
    "# new_modules = list(newmodel.modules())\n",
    "\n",
    "# layer_id_in_cfg = 0\n",
    "# start_mask = torch.ones(3) #3為input channel(R,G,B)\n",
    "# end_mask = cfg_mask[layer_id_in_cfg]\n",
    "# bn_count = 0\n",
    "# for layer_id in range(len(old_modules)):\n",
    "\n",
    "#     m0 = old_modules[layer_id]\n",
    "#     m1 = new_modules[layer_id]\n",
    "\n",
    "#     if isinstance(m0, nn.BatchNorm2d):\n",
    "#         bn_count += 1\n",
    "\n",
    "#         #### 找出遮罩中非零元素的index ####\n",
    "#         ################################################\n",
    "#         #          請填空          #\n",
    "#         ################################################\n",
    "#         idx = np.squeeze(np.argwhere(np.asarray(mask.cpu().numpy())))\n",
    "#         if idx.size == 1:  # 若僅剩一個通道，確保維度正確\n",
    "#             idx = np.resize(idx, (1,))\n",
    "        \n",
    "#         # #### 複製weight, bias, running mean,and running variance ####\n",
    "#         # ################################################\n",
    "#         # #          請填空          #\n",
    "#         # ################################################\n",
    "#         new_bn.weight.data = old_bn.weight.data[idx.tolist()].clone()\n",
    "#         new_bn.bias.data   = old_bn.bias.data[idx.tolist()].clone()\n",
    "#         new_bn.running_mean = old_bn.running_mean[idx.tolist()].clone()\n",
    "#         new_bn.running_var  = old_bn.running_var[idx.tolist()].clone()\n",
    "\n",
    "#         layer_id_in_cfg += 1\n",
    "#         start_mask = end_mask.clone()\n",
    "\n",
    "#         #最後一層連接層不做修改\n",
    "#         if layer_id_in_cfg < len(cfg_mask):\n",
    "#             end_mask = cfg_mask[layer_id_in_cfg]\n",
    "\n",
    "#     elif isinstance(m0, nn.Conv2d):\n",
    "#         if isinstance(old_modules[layer_id + 1], nn.BatchNorm2d):\n",
    "#             print(f\"m0: {m0}\")\n",
    "#             print(f\"m1: {m1}\")\n",
    "#             print(f\"\\n[Layer {layer_id}] Conv2d pruning\")\n",
    "#             print(f\"start_mask: {start_mask.shape}, sum={start_mask.sum().item()}\")\n",
    "#             print(f\"type(end_mask)={type(end_mask)} | device={end_mask.device} | dtype={end_mask.dtype}\")\n",
    "#             try:\n",
    "#                 end_mask_cpu = end_mask.detach().cpu()\n",
    "#                 print(f\"end_mask (cpu): {end_mask_cpu}\")\n",
    "#                 print(f\"end_mask shape: {end_mask_cpu.shape}, sum={end_mask_cpu.sum().item()}\")\n",
    "#             except Exception as e:\n",
    "#                 print(\"[ERROR] Moving end_mask to CPU failed\")\n",
    "#                 raise e\n",
    "\n",
    "#             print(f\"end_mask: {end_mask.shape}, sum={end_mask.sum().item()}\")\n",
    "#             idx0 = np.squeeze(np.argwhere(np.asarray(start_mask.cpu().numpy())))\n",
    "#             idx1 = np.squeeze(np.argwhere(np.asarray(end_mask.cpu().numpy())))\n",
    "#             #### 複製weight ####\n",
    "#             ################################################\n",
    "#             #          請填空          #\n",
    "#             ################################################\n",
    "#             if idx0.ndim == 0:\n",
    "#                 idx0 = np.expand_dims(idx0, 0)\n",
    "#             if idx1.ndim == 0:\n",
    "#                 idx1 = np.expand_dims(idx1, 0)\n",
    "            \n",
    "#             w = m0.weight.data[idx1.tolist(), :, :, :].clone()\n",
    "#             w = w[:, idx0.tolist(), :, :].clone()\n",
    "\n",
    "#             m1.weight.data = w.clone()  # 這行很重要！\n",
    "\n",
    "#               # downsample 層不用prune\n",
    "#         else:\n",
    "#             m1.weight.data = m0.weight.data.clone()\n",
    "\n",
    "#     elif isinstance(m0, nn.Linear):\n",
    "\n",
    "#         idx0 = np.squeeze(np.argwhere(np.asarray(start_mask.cpu().numpy())))\n",
    "#         if idx0.ndim == 0:\n",
    "#             idx0 = np.expand_dims(idx0, 0)\n",
    "\n",
    "#         #### 複製weight ####\n",
    "#         ################################################\n",
    "#         #          請填空          #\n",
    "#         ################################################\n",
    "#         m1.weight.data = m0.weight.data[:, idx0].clone()\n",
    "\n",
    "#         #### 複製bias ####\n",
    "#         m1.bias.data = m0.bias.data.clone()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U0nUbcNtA_SA"
   },
   "source": [
    "## 測試函數\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Md44Lc-WBIaf"
   },
   "outputs": [],
   "source": [
    "def test(model):\n",
    "    kwargs = {'num_workers': 1, 'pin_memory': True} if CUDA else {}\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.CIFAR10('./data', train=False, download=True, transform=transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])),\n",
    "        batch_size=TEST_BATCH_SIZE, shuffle=True, **kwargs)\n",
    "\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "      for data, target in test_loader:\n",
    "          if CUDA:\n",
    "              data, target = data.cuda(), target.cuda()\n",
    "          data, target = Variable(data), Variable(target)\n",
    "          output = model(data)\n",
    "          pred = output.data.max(1, keepdim=True)[1]\n",
    "          correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    print('\\nTest set: Accuracy: {}/{} ({:.1f}%)\\n'.format(\n",
    "        correct, len(test_loader.dataset), 100. * correct / len(test_loader.dataset)))\n",
    "    return correct / float(len(test_loader.dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AFkMmFLo88mc"
   },
   "source": [
    "## 儲存模型並印出結果，以及剪枝後的test acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "cuo3HXHt9Ar-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cfg:  [64, 64, 64, 256, 64, 64, 256, 64, 64, 256, 117, 121, 512, 92, 121, 512, 69, 75, 512, 69, 71, 512, 66, 63, 1024, 14, 24, 1024, 1, 8, 1024, 1, 8, 1024, 3, 2, 1024, 3, 3, 1024, 4, 2, 2048, 3, 3, 2048, 3, 3, 2048]\n",
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 117, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(117, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(117, 121, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(121, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(121, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 92, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(92, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(92, 121, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(121, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(121, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 69, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(69, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(69, 75, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(75, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(75, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 69, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(69, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(69, 71, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(71, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(71, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 66, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(66, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(66, 63, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(63, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(63, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 14, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(14, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(24, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(8, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(8, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(3, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(2, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(3, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(4, 2, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(2, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(3, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(3, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=10, bias=True)\n",
      ")\n",
      "\n",
      "Test set: Accuracy: 2608/10000 (26.1%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.2608)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"cfg: \", cfg)\n",
    "torch.save({'cfg': cfg, 'state_dict': newmodel.state_dict()}, PRUNE_PATH)\n",
    "\n",
    "print(newmodel)\n",
    "model = newmodel.cuda()\n",
    "test(model)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
